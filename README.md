# TEXT-SUMMARIZATION-TOOL

"COMPANY":CODETECH IT SOLUTIONS

"NAME":THUMATI MAHITHA

"INTERN ID":CT04DL756

"DOMAIN NAME ":ARTIFICIAL INTELLIGENCE

"DURATION":4 WEEKS

"MENTOR":NEELA SANTHOSH KUMAR

## I HAVE DONE THE TEXT SUMMARIZATION TOOL.THIS TASK WAS PERFORMED USING PYTHON PLATFORM JUPYTER NOTEBOOK.Tool/Library are `nltk`, `re` (Regex)  ,`heapq` and the purposes of those tools:                            
 `nltk`: Natural Language Toolkit for tokenization, stopword filtering, and sentence segmentation. 
 `re` (Regex):For cleaning and preprocessing the input text.                                            
 `heapq`:To extract top scoring sentences efficiently (used for prioritization).                                                                      
## functions which are used in the task are:
sent_tokenize(text)	
word_tokenize(text)
stopwords.words('english')	
heapq.nlargest()
The code does not generate new sentences but picks the most relevant ones from the original text.
Itâ€™s based on word frequency scoring, which assumes that the most frequently occurring meaningful words contribute to a sentence's importance.
## OUTPUT:
========= TEXT SUMMARIZATION TOOL ==========

Paste your article or paragraph:

 Artificial Intelligence (AI) is a branch of computer science that aims to create machines that can perform tasks that typically require human intelligence. These tasks include learning, reasoning, problem-solving, perception, and language understanding. AI has numerous applications in various domains including healthcare, finance, education, and transportation. In recent years, the development of machine learning and deep learning has significantly advanced the field of AI. Companies and governments are investing heavily in AI research and development. As AI continues to evolve, ethical considerations and regulations are becoming increasingly important.
